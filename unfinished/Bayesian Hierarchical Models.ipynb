{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus discussion: Hierarchical Modeling\n",
    "\n",
    "Up to this point we've examine problems similar to those we've seen before, calculating means and standard deviations and linear fits, though done in a probabilitic way, rather than just finding the \"best\" (MLE) parameters. Here we consider a problem beyond that.\n",
    "\n",
    "Consider the scores of five classes of students on a test. The test is the same, but the students have different teachers, classrooms, materials, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.read_csv('data/scores.csv')\n",
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.score.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might wonder whether different teachers and such have a significant effect on the scores.\n",
    "\n",
    "**Discussion:** How would we approach the as frequentists?\n",
    "\n",
    "As Bayesians, we can choose a more nuanced approach. Rather than testing a null hypothesis that all classes are same, or just assuming they each have their own independent mean, we can assume the mean for each class (`eta1`...`eta5`) is drawn from a single (unknown) normal distribution. So data from each of the classes are drawn from a different normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = df_scores.values\n",
    "\n",
    "with pm.Model() as model_scores:\n",
    "    mu = pm.Uniform('mu', 0, 1)\n",
    "    sigma = pm.HalfNormal('sigma', 1)\n",
    "    sd = pm.HalfNormal('sd', 1)\n",
    "    eta1 = pm.Normal('eta1', 0, 1)\n",
    "    eta2 = pm.Normal('eta2', 0, 1)\n",
    "    eta3 = pm.Normal('eta3', 0, 1)\n",
    "    eta4 = pm.Normal('eta4', 0, 1)\n",
    "    eta5 = pm.Normal('eta5', 0, 1)\n",
    "    theta1 = pm.Deterministic('theta1', mu + )\n",
    "    theta2 = pm.Normal('eta2', 0, 1)\n",
    "    eta3 = pm.Normal('eta3', 0, 1)\n",
    "    eta4 = pm.Normal('eta4', 0, 1)\n",
    "    eta5 = pm.Normal('eta5', 0, 1)\n",
    "    obs1 = pm.Normal('obs1', eta1, sd, observed=scores[scores[:,0]==1, 1])\n",
    "    obs2 = pm.Normal('obs2', eta2, sd, observed=scores[scores[:,0]==2, 1])\n",
    "    obs3 = pm.Normal('obs3', eta3, sd, observed=scores[scores[:,0]==3, 1])\n",
    "    obs4 = pm.Normal('obs4', eta4, sd, observed=scores[scores[:,0]==4, 1])\n",
    "    obs5 = pm.Normal('obs5', eta5, sd, observed=scores[scores[:,0]==5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_scores:\n",
    "    trace = pm.sample(5000, tune=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
